from __future__ import print_function

import numpy as np
import os
import xml.etree.ElementTree as ET

import torch
import torch.nn
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms


class VOCDataset(Dataset):
    CLASS_NAMES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',
                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']
    INV_CLASS = {}
    for i in range(len(CLASS_NAMES)):
        INV_CLASS[CLASS_NAMES[i]] = i

    def __init__(self, split, size, data_dir='VOCdevkit/VOC2007/'):
        super().__init__()
        self.split = split
        self.data_dir = data_dir
        self.size = size
        self.img_dir = os.path.join(data_dir, 'JPEGImages')
        self.ann_dir = os.path.join(data_dir, 'Annotations')

        split_file = os.path.join(data_dir, 'ImageSets/Main', split + '.txt')
        with open(split_file) as fp:
            self.index_list = [line.strip() for line in fp]

        self.anno_list = self.preload_anno()

        self.size = 227
        
        # self.train_transform = transforms.Compose([transforms.Resize((self.size,self.size)), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor()])
        # self.test_transform = transforms.Compose([transforms.CenterCrop((self.size,self.size)), transforms.Resize((self.size,self.size)), transforms.ToTensor()])
        self.train_transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5)])
        self.test_transform = transforms.Compose([transforms.CenterCrop((self.size,self.size))])

    @classmethod
    def get_class_name(cls, index):
        return cls.CLASS_NAMES[index]

    @classmethod
    def get_class_index(cls, name):
        return cls.INV_CLASS[name]

    def __len__(self):
        return len(self.index_list)

    def preload_anno(self):
        """
        :return: a list of lables. each element is in the form of [class, weight],
         where both class and weight are a numpy array in shape of [20],
        """
        label_list = []

        for index in self.index_list:
            class_names = set()
            occurence_dict = {}
            difficult_dict = {}

            class_labels = np.zeros(20)
            weights = np.ones(20)
            fpath = os.path.join(self.ann_dir, index + '.xml')
            tree = ET.parse(fpath)
            root = tree.getroot()
            
            for obj in root.findall('object'):
                obj_name = obj.find('name').text
                class_names.add(obj_name)
                if not obj_name in occurence_dict:
                    occurence_dict[obj_name] = 1
                    difficult_dict[obj_name] = 0
                else:
                    occurence_dict[obj_name] += 1
                difficulty = int(obj.find("difficult").text)
                occurence_dict[obj_name] += difficulty
                class_idx = self.get_class_index(obj_name)
                class_labels[class_idx] = 1

            for c_name in class_names:
                if occurence_dict[c_name] == difficult_dict[c_name]:
                    class_idx = self.get_class_index(obj_name)
                    weights[class_idx] = 0

            label_list.append([class_labels, weights])
        return label_list

    def __getitem__(self, index):
        """
        :param index: a int generated by Dataloader in range [0, __len__()]
        :return: index-th element
        image: FloatTensor in shape of (C, H, W) in scale [-1, 1].
        label: LongTensor in shape of (Nc, ) binary label
        weight: FloatTensor in shape of (Nc, ) difficult or not.
        """
        findex = self.index_list[index]
        fpath = os.path.join(self.img_dir, findex + '.jpg')

        lab_vec, wgt_vec = self.anno_list[index]
        img = Image.open(fpath)
        if(self.split == 'trainval'):
            img = self.train_transform(img)
        # if(self.split == 'test'):
            # img = self.test_transform(img)

        img = transforms.functional.resize(img, size=(self.size,self.size))
        img = transforms.functional.to_tensor(img)
        image = torch.FloatTensor(img)
        img = transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
        label = torch.FloatTensor(lab_vec)
        wgt = torch.FloatTensor(wgt_vec)
        return image, label, wgt

